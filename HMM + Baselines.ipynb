{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HMM Section w/ Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import Counter, defaultdict\n",
    "import numpy as np\n",
    "\n",
    "#PREPROCESSING\n",
    "categories = [\"O\", \"B-MISC\", \"I-MISC\", \"B-ORG\", \"I-ORG\", \"B-LOC\", \"I-LOC\", \"B-PER\", \"I-PER\"]\n",
    "tsv_file = open('train.txt', encoding=\"utf8\")\n",
    "tsv_reader = csv.reader(tsv_file, delimiter='\\t', quotechar=None)\n",
    "vocabulary = []\n",
    "vocabulary2 = []\n",
    "train = []\n",
    "validation = []\n",
    "validation_tags = []\n",
    "baseline_lines = []\n",
    "baseline2_lines = []\n",
    "train_count_tags = defaultdict(float)\n",
    "train_count_words = defaultdict(float)\n",
    "train_tag_bigram = defaultdict(lambda: defaultdict(float))\n",
    "val_tag_bigram = defaultdict(lambda: defaultdict(float))\n",
    "train_words = defaultdict(lambda: defaultdict(float))\n",
    "val_words = defaultdict(lambda: defaultdict(float))\n",
    "val = False\n",
    "i = 0\n",
    "line = []\n",
    "for row in tsv_reader:\n",
    "    if i % 3 == 0: # Only the 3rd line contains the actual sentences\n",
    "        line = []\n",
    "        if i % 15 == 0: # Every 15th word line is set aside for validation set\n",
    "            val = True\n",
    "        else:\n",
    "            val = False\n",
    "        if not val:\n",
    "            for element in row:\n",
    "                if element not in vocabulary2:\n",
    "                    vocabulary2.append(element)\n",
    "                    num2 = np.random.randint(0,100)\n",
    "                    if num2 < 30:                      # 30% chance to replace unique words with <UNK>\n",
    "                        line.append(\"<UNK>\")\n",
    "                        train_count_words[\"<UNK>\"] += 1\n",
    "                        continue\n",
    "                train_count_words[element] += 1\n",
    "                line.append(element)\n",
    "            train.append(row)\n",
    "        else:\n",
    "            for element in row:\n",
    "                line.append(element)\n",
    "            validation.append(line)\n",
    "    if i % 3 == 2: #dealing with the BIO tags in the training set\n",
    "        line_index = 0\n",
    "        previous_tag = \"<s>\" #only adding start tags to the very first entry\n",
    "        if val:\n",
    "            validation_tags.append(row)\n",
    "        for element in row:\n",
    "            if not val:\n",
    "#                 print(line[line_index])\n",
    "                train_words[line[line_index]][element] += 1\n",
    "                train_tag_bigram[element][previous_tag] += 1\n",
    "                previous_tag = element\n",
    "                train_count_tags[element] += 1\n",
    "            else:\n",
    "                val_words[line[line_index]][element] += 1\n",
    "                val_tag_bigram[element][previous_tag] += 1\n",
    "                previous_tag = element\n",
    "            line_index += 1\n",
    "    i += 1\n",
    "for i in vocabulary2: # Goes back through the vocabulary and removes words that only appeared once and were replaced with <UNK> tags\n",
    "    if not train_count_words[i] == 0:\n",
    "        vocabulary.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating + getting probability counts for the tag bigrams and words given tags\n",
    "k = 2\n",
    "    \n",
    "train_tag_bigram_prob = defaultdict(lambda: defaultdict(float))\n",
    "train_words_prob = defaultdict(lambda: defaultdict(float))\n",
    "for first in train_tag_bigram:\n",
    "    for tag in categories:\n",
    "        count = train_tag_bigram[first][tag]\n",
    "        train_tag_bigram_prob[first][tag] = (count+k)/(train_count_tags[first]+k*(len(categories)+1))\n",
    "    train_tag_bigram_prob[first][\"<s>\"]= (count+k)/(train_count_tags[first]+k*(len(categories)+1))\n",
    "k = 0.0001\n",
    "\n",
    "for first in train_words:\n",
    "    for tag in categories:\n",
    "        count = train_words[first][tag]\n",
    "        train_words_prob[first][tag] = (count+k)/(train_count_words[first]+k*len(vocabulary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our first Baseline Model\n",
    "def baseline(line):\n",
    "    tags = []\n",
    "    for element in line:\n",
    "        if element not in vocabulary:\n",
    "            element = \"<UNK>\"\n",
    "        if element == \"<UNK>\":\n",
    "            tags.append(\"O\")\n",
    "        else:\n",
    "            vals = train_words[element]\n",
    "            most_likely = max(vals, key=train_words[element].get)\n",
    "            tags.append(most_likely)\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our 2nd Baseline Model\n",
    "def baseline2(line):\n",
    "    tags = []\n",
    "    for element in line:\n",
    "        if element not in vocabulary:\n",
    "            element = \"<UNK>\"\n",
    "        if element == \"<UNK>\":\n",
    "            tags.append(\"O\")\n",
    "        else:\n",
    "            tags.append(np.random.choice(list(train_words[element])))\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used in Viterbi to find the maximum score\n",
    "def max_score(score,index, tag):\n",
    "    scores = [0,0,0,0,0,0,0,0,0]\n",
    "    for i in range(9):\n",
    "        scores[i] = score[i][index-1]*train_tag_bigram_prob[tag][categories[i]]\n",
    "    return max(scores), np.argmax(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HMM Viterbi Algorithm\n",
    "def viterbi(line):\n",
    "    backpointer = np.zeros([len(categories), len(line)])\n",
    "    score = np.zeros([len(categories), len(line)])\n",
    "    for i in range(len(line)):\n",
    "        if line[i] not in vocabulary:\n",
    "            line[i] = \"<UNK>\"\n",
    "    for i in range(len(categories)):\n",
    "        score[i][0] = train_tag_bigram_prob[categories[i]][\"<s>\"]*train_words_prob[line[0]][categories[i]]\n",
    "    if len(line) == 1:\n",
    "        maxscore, maxpointer = max_score(score, 0, categories[i])\n",
    "    for t in range(1, len(line)):\n",
    "        for i in range(len(categories)):\n",
    "            maxscore, maxpointer = max_score(score, t, categories[i])\n",
    "            score[i][t] = maxscore*train_words_prob[line[t]][categories[i]]\n",
    "            backpointer[i][t] = maxpointer\n",
    "    sequence = np.zeros(len(line))\n",
    "    max_s = 0\n",
    "    max_index = 0\n",
    "    for i in range(9):\n",
    "        if max_s < score[i][len(line)-1]:\n",
    "            max_s = score[i][len(line)-1]\n",
    "            max_index = i\n",
    "    sequence[len(line)-1] = max_index\n",
    "    char_sequence = []\n",
    "    for i in range(len(line)-2, -1, -1):\n",
    "        sequence[i] = backpointer[int(sequence[i+1])][i+1]\n",
    "    for i in range(len(line)):\n",
    "        char_sequence.append(categories[int(sequence[i])])\n",
    "    return char_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculated Precision, Recall, F-Score\n",
    "def check_val(method,validation, validation_tags):\n",
    "    correct = 0\n",
    "    guessed = 0\n",
    "    total = 0\n",
    "    for i in range(len(validation)):\n",
    "        tags = []\n",
    "        if method == 'viterbi':\n",
    "            guess_line = viterbi(validation[i])\n",
    "        elif method == 'baseline1':\n",
    "            guess_line = baseline(validation[i])\n",
    "        else:\n",
    "            guess_line = baseline2(validation[i])\n",
    "        for tag in range(len(guess_line)):\n",
    "            if \"PER\" in guess_line[tag]:\n",
    "                tags.append(\"PER\")\n",
    "            elif \"LOC\" in guess_line[tag]:\n",
    "                tags.append(\"LOC\")\n",
    "            elif \"ORG\" in guess_line[tag]:\n",
    "                tags.append(\"ORG\")\n",
    "            elif \"MISC\" in guess_line[tag]:\n",
    "                tags.append(\"MISC\")\n",
    "            else:\n",
    "                tags.append(\"O\")\n",
    "        for tag in range(len(validation_tags[i])):\n",
    "            if \"PER\" in validation_tags[i][tag]:\n",
    "                validation_tags[i][tag] = \"PER\"\n",
    "            elif \"LOC\" in validation_tags[i][tag]:\n",
    "                validation_tags[i][tag] = \"LOC\"\n",
    "            elif \"ORG\" in validation_tags[i][tag]:\n",
    "                validation_tags[i][tag] = \"ORG\"\n",
    "            elif \"MISC\" in validation_tags[i][tag]:\n",
    "                validation_tags[i][tag] = \"MISC\"\n",
    "            else:\n",
    "                validation_tags[i][tag] = \"O\"\n",
    "        for tag in range(len(validation_tags[i])):\n",
    "            if tags[tag] == \"O\":\n",
    "                continue\n",
    "            correct += (tags[tag] == validation_tags[i][tag])\n",
    "        for j in guess_line:\n",
    "            if not j == 'O':\n",
    "                guessed += 1\n",
    "        for k in validation_tags[i]:\n",
    "            if not k == 'O':\n",
    "                total += 1\n",
    "    precision = correct/guessed\n",
    "    recall = correct/total\n",
    "    fscore = 2*precision*recall/(precision+recall)\n",
    "    return precision, recall, fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9064828614008942 0.7161147902869757 0.8001315464934639\n"
     ]
    }
   ],
   "source": [
    "precision, recall, fscore = check_val('viterbi', validation, validation_tags)\n",
    "print(precision, recall, fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.866642958748222 0.7172921265636497 0.7849263225702552\n"
     ]
    }
   ],
   "source": [
    "precision, recall, fscore = check_val('baseline1', validation, validation_tags)\n",
    "print(precision, recall, fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03860002441108263 0.1861662987490802 0.06394217403391715\n"
     ]
    }
   ],
   "source": [
    "precision, recall, fscore = check_val('baseline2', validation, validation_tags)\n",
    "print(precision, recall, fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Executing HMM on test set\n",
    "tsv_file = open('test.txt', encoding=\"utf8\")\n",
    "tsv_reader = csv.reader(tsv_file, delimiter='\\t', quotechar=None)\n",
    "PER = []\n",
    "LOC = []\n",
    "ORG = []\n",
    "MISC = []\n",
    "indices = []\n",
    "display = []\n",
    "tags = []\n",
    "i = 0\n",
    "#Obtaining tag predictions for each line using Viterbi\n",
    "for row in tsv_reader:\n",
    "    if i%3 == 0:\n",
    "        line = []\n",
    "        for element in row:\n",
    "            if element not in vocabulary:\n",
    "                line.append(\"<UNK>\")\n",
    "            else:\n",
    "                line.append(element)\n",
    "        line_tags = viterbi(line)\n",
    "        display.append(line_tags)\n",
    "        for tag in line_tags:\n",
    "            tags.append(tag)\n",
    "    i+=1\n",
    "tsv_file = open('test.txt', encoding=\"utf8\")\n",
    "i = 0\n",
    "tsv_reader = csv.reader(tsv_file, delimiter=' ', quotechar=None)\n",
    "for row in tsv_reader: #obtaining indices from test.txt\n",
    "    if i%3 == 2:\n",
    "        for element in row:\n",
    "            indices.append(element)\n",
    "    i+= 1\n",
    "for i in range(len(tags)):\n",
    "    if \"PER\" in tags[i]:\n",
    "         tags[i] = \"PER\"\n",
    "    elif \"LOC\" in  tags[i]:\n",
    "         tags[i] = \"LOC\"\n",
    "    elif \"ORG\" in  tags[i]:\n",
    "         tags[i] = \"ORG\"\n",
    "    elif \"MISC\" in  tags[i]:\n",
    "         tags[i] = \"MISC\"\n",
    "    else:\n",
    "         tags[i] = \"O\"\n",
    "beginning = False\n",
    "log_tag = \"\"\n",
    "end = \"\"\n",
    "begin = \"\"\n",
    "intermediate = False\n",
    "#Converting tags for submission\n",
    "for i in range(len(tags)):\n",
    "    if beginning and log_tag == tags[i]:\n",
    "        end = str(indices[i])\n",
    "    if beginning and not log_tag == tags[i]:\n",
    "        beginning = False\n",
    "        if \"PER\" in log_tag:\n",
    "            PER.append(begin+end)\n",
    "        elif \"LOC\" in log_tag:\n",
    "            LOC.append(begin+end)\n",
    "        elif \"ORG\" in log_tag:\n",
    "            ORG.append(begin+end)\n",
    "        elif \"MISC\" in log_tag:\n",
    "            MISC.append(begin+end)\n",
    "    if beginning == False and not tags[i] == 'O':\n",
    "        beginning = True\n",
    "        log_tag = tags[i]\n",
    "        begin = str(indices[i]) + \"-\"\n",
    "        end = str(indices[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating CSV\n",
    "csv_per = \"\"\n",
    "csv_loc = \"\"\n",
    "csv_org = \"\"\n",
    "csv_misc = \"\"\n",
    "for i in PER:\n",
    "    csv_per += i + \" \"\n",
    "for i in LOC:\n",
    "    csv_loc += i + \" \"\n",
    "for i in ORG:\n",
    "    csv_org += i + \" \"\n",
    "for i in MISC:\n",
    "    csv_misc += i + \" \"\n",
    "with open('preds_idk.csv', 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile)\n",
    "    spamwriter.writerow([\"Type\", \"Prediction\"])\n",
    "    spamwriter.writerow([\"PER\", csv_per])\n",
    "    spamwriter.writerow([\"LOC\", csv_loc])\n",
    "    spamwriter.writerow([\"ORG\", csv_org])\n",
    "    spamwriter.writerow([\"MISC\", csv_misc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(display[45])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
