{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MEMM + Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import Counter, defaultdict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing to obtain validation counts/validation set\n",
    "categories = [\"B-LOC\", \"B-MISC\", \"B-ORG\", \"B-PER\", \"I-LOC\", \"I-MISC\", \"I-ORG\", \"I-PER\", \"O\"]\n",
    "tsv_file = open('train.txt', encoding=\"utf8\")\n",
    "tsv_reader = csv.reader(tsv_file, delimiter='\\t', quotechar=None)\n",
    "vocabulary = []\n",
    "vocabulary2 = []\n",
    "train = []\n",
    "validation = []\n",
    "validation_pos = []\n",
    "validation_tags = []\n",
    "baseline_lines = []\n",
    "baseline2_lines = []\n",
    "train_count_tags = defaultdict(float)\n",
    "train_count_words = defaultdict(float)\n",
    "train_tag_bigram = defaultdict(lambda: defaultdict(float))\n",
    "val_tag_bigram = defaultdict(lambda: defaultdict(float))\n",
    "train_words = defaultdict(lambda: defaultdict(float))\n",
    "val_words = defaultdict(lambda: defaultdict(float))\n",
    "val = False\n",
    "i = 0\n",
    "line = []\n",
    "for row in tsv_reader:\n",
    "    if i % 3 == 0:\n",
    "        line = []\n",
    "        if i % 15 == 0:\n",
    "            val = True\n",
    "        else:\n",
    "            val = False\n",
    "        if not val:\n",
    "            for element in row:\n",
    "                if element not in vocabulary2:\n",
    "                    vocabulary2.append(element)\n",
    "                    num2 = np.random.randint(0,100)\n",
    "                    if num2 < 30:\n",
    "                        line.append(\"<UNK>\")\n",
    "                        train_count_words[\"<UNK>\"] += 1\n",
    "                        continue\n",
    "                train_count_words[element] += 1\n",
    "                line.append(element)\n",
    "            train.append(row)\n",
    "        else:\n",
    "            for element in row:\n",
    "                line.append(element)\n",
    "            validation.append(line)\n",
    "    if i %3 == 1 and val:\n",
    "        validation_pos.append(line)\n",
    "    if i % 3 == 2:\n",
    "        line_index = 0\n",
    "        previous_tag = \"<s>\" #only adding start tags to the very first entry\n",
    "        if val:\n",
    "            validation_tags.append(row)\n",
    "        for element in row:\n",
    "            if not val:\n",
    "                train_words[line[line_index]][element] += 1\n",
    "                train_tag_bigram[element][previous_tag] += 1\n",
    "                previous_tag = element\n",
    "                train_count_tags[element] += 1\n",
    "            else:\n",
    "                val_words[line[line_index]][element] += 1\n",
    "                val_tag_bigram[element][previous_tag] += 1\n",
    "                previous_tag = element\n",
    "            line_index += 1\n",
    "    i += 1\n",
    "for i in vocabulary2:\n",
    "    if not train_count_words[i] == 0:\n",
    "        vocabulary.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to calculate word shape as a feature\n",
    "def shape(word):\n",
    "    word_shape = 'other'\n",
    "    if re.match('[0-9]+(\\.[0-9]*)?|[0-9]*\\.[0-9]+$', word):\n",
    "        word_shape = 'number'\n",
    "    elif re.match('\\W+$', word):\n",
    "        word_shape = 'punct'\n",
    "    elif re.match('[A-Z][a-z]+$', word):\n",
    "        word_shape = 'capitalized'\n",
    "    elif re.match('[A-Z]+$', word):\n",
    "        word_shape = 'uppercase'\n",
    "    elif re.match('[a-z]+$', word):\n",
    "        word_shape = 'lowercase'\n",
    "    elif re.match('[A-Z][a-z]+[A-Z][a-z]+[A-Za-z]*$', word):\n",
    "        word_shape = 'camelcase'\n",
    "    elif re.match('[A-Za-z]+$', word):\n",
    "        word_shape = 'mixedcase'\n",
    "    elif re.match('__.+__$', word):\n",
    "        word_shape = 'wildcard'\n",
    "    elif re.match('[A-Za-z0-9]+\\.$', word):\n",
    "        word_shape = 'ending-dot'\n",
    "    elif re.match('[A-Za-z0-9]+\\.[A-Za-z0-9\\.]+\\.$', word):\n",
    "        word_shape = 'abbreviation'\n",
    "    elif re.match('[A-Za-z0-9]+\\-[A-Za-z0-9\\-]+.*$', word):\n",
    "        word_shape = 'contains-hyphen'\n",
    "    return word_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.txt','r') as file:\n",
    "        train =[x.strip().split('\\t') for x in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERTING TRAINING SET TO FEATURES FOR OUR LOGISTIC REGRESSION MODEL\n",
    "import re\n",
    "\n",
    "training_x = []\n",
    "training_y = []\n",
    "train_set = []\n",
    "for i in range(len(train)):\n",
    "    if i%3 == 0 and not i%15 == 0:\n",
    "        for j in range(len(train[i])):\n",
    "            feature_dictionary = defaultdict(int)\n",
    "            features = []\n",
    "            #features.append(train[i][j])#word itself\n",
    "            if j >0:\n",
    "                #previous bio tag\n",
    "                features.append(int(train[i+2][j-1]=='B-ORG')) \n",
    "                features.append(int(train[i+2][j-1]=='B-PER'))\n",
    "                features.append(int(train[i+2][j-1]=='B-LOC'))\n",
    "                features.append(int(train[i+2][j-1]=='B-MISC'))\n",
    "                features.append(int(train[i+2][j-1]=='I-ORG'))\n",
    "                features.append(int(train[i+2][j-1]=='I-PER'))\n",
    "                features.append(int(train[i+2][j-1]=='I-LOC'))\n",
    "                features.append(int(train[i+2][j-1]=='I-MISC'))\n",
    "                features.append(int(train[i+2][j-1]=='O'))\n",
    "                features.append(int((train[i+1][j-1])=='NNP'))# previous part of speech\n",
    "                features.append(int((train[i+1][j-1])=='NNPS'))\n",
    "                features.append((int((train[i+1][j-1])=='IN')))\n",
    "                features.append((int((train[i+1][j-1])=='JJ')))\n",
    "                features.append((int((train[i+1][j-1])=='VB')))\n",
    "                features.append((int((train[i+1][j-1])=='VBD')))\n",
    "                features.append(int(train[i][j-1]==','))\n",
    "#                 features.append(len(train[i][j-1]))\n",
    "                features.append(int(train[i][j-1][0].isupper()))#first letter capital\n",
    "                features.append(int(train[i][j-1].isupper()))#whole word capitalized\n",
    "                features.append(int(shape(train[i][j-1]) == 'abbreviation'))\n",
    "                features.append(int(shape(train[i][j-1]) == 'ending-dot'))\n",
    "                features.append(int(shape(train[i][j-1]) == 'wildcard'))\n",
    "                features.append(int(shape(train[i][j-1]) == 'mixedcase'))\n",
    "                features.append(int(shape(train[i][j-1]) == 'camelcase'))\n",
    "                features.append(int(shape(train[i][j-1]) == 'number'))\n",
    "                features.append(int(shape(train[i][j-1]) == 'punct'))\n",
    "                \n",
    "                \n",
    "                if j < len(train[i])-1:\n",
    "                    features.append(int((train[i+1][j+1])=='NNP'))# previous part of speech\n",
    "                    features.append(int((train[i+1][j+1])=='NNPS'))\n",
    "                    features.append((int((train[i+1][j+1])=='IN')))\n",
    "                    features.append((int((train[i+1][j+1])=='JJ')))\n",
    "                    features.append((int((train[i+1][j+1])=='POS')))\n",
    "                    features.append((int((train[i+1][j+1])=='RB')))\n",
    "                    features.append((int((train[i+1][j+1])=='VB')))\n",
    "                    features.append((int((train[i+1][j+1])=='VBD')))\n",
    "                    \n",
    "                    features.append(int(train[i][j+1]==','))\n",
    "                    features.append(int(train[i][j+1][0].isupper()))#first letter capital\n",
    "                    features.append(int(train[i][j+1].isupper()))#whole word capitalized\n",
    "                    features.append(int(shape(train[i][j+1]) == 'abbreviation'))\n",
    "                    features.append(int(shape(train[i][j+1]) == 'ending-dot'))\n",
    "                    features.append(int(shape(train[i][j+1]) == 'wildcard'))\n",
    "                    features.append(int(shape(train[i][j+1]) == 'mixedcase'))\n",
    "                    features.append(int(shape(train[i][j+1]) == 'camelcase'))\n",
    "                    features.append(int(shape(train[i][j+1]) == 'number'))\n",
    "                    features.append(int(shape(train[i][j+1]) == 'punct'))\n",
    "                else:\n",
    "                    for l in range(25,43):\n",
    "                        features.append(0)\n",
    "            else:\n",
    "                for l in range (0,43):\n",
    "                    features.append(0)\n",
    "            features.append(int((train[i+1][j])=='NNP'))\n",
    "            features.append(int((train[i+1][j])=='NNPS'))\n",
    "            features.append(int(train[i][j][0].isupper()))#first letter capital\n",
    "            features.append(int(train[i][j].isupper()))#whole word capitalized\n",
    "            features.append(int('-' in train[i][j] and (len(train[i][j])>0)))\n",
    "            features.append(len(train[i][j]))\n",
    "            features.append(int(train[i][j].isalpha()))\n",
    "            features.append(int(shape(train[i][j]) == 'abbreviation'))\n",
    "            features.append(int(shape(train[i][j]) == 'ending-dot'))\n",
    "            features.append(int(shape(train[i][j]) == 'wildcard'))\n",
    "            features.append(int(shape(train[i][j]) == 'mixedcase'))\n",
    "            features.append(int(shape(train[i][j]) == 'camelcase'))\n",
    "            features.append(int(shape(train[i][j]) == 'number'))\n",
    "            features.append(int(shape(train[i][j]) == 'punct'))\n",
    "           \n",
    "            tupled = feature_dictionary, train[i+2][j]\n",
    "            train_set.append(tupled)\n",
    "            training_x.append(features)\n",
    "            training_y.append(train[i+2][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.921864801865\n"
     ]
    }
   ],
   "source": [
    "# RUNNING LOGISTIC REGRESSION CLASSIFICATION MODEL ON OUR TRAINING SET\n",
    "X = training_x\n",
    "y = training_y\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "clf = LogisticRegression(random_state=0, multi_class='multinomial', solver='newton-cg')\n",
    "\n",
    "model = clf.fit(X, y)\n",
    "print(model.score(X_val,y_val)) # CALCULATING MODEL ACCURACY ON PRE-MADE VALIDATION SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERTING TEST SET TO FEATURES FOR MAXENT MODEL\n",
    "with open('test.txt','r') as file:\n",
    "        test =[x.strip().split('\\t') for x in file]\n",
    "final_preds = []\n",
    "\n",
    "tests_x = []\n",
    "\n",
    "testing_x = []\n",
    "predictions = []\n",
    "for m in range (0, len(test)):\n",
    "    idk_x = []\n",
    "    mini_preds = []\n",
    "    semifinal_preds = []\n",
    "    if m%3 == 0:\n",
    "        for n in range(len(test[m])):\n",
    "            test_features = []\n",
    "            currentIndex = int(''.join(test[m+2]).split(' ')[0]) + n\n",
    "            if n > 0:\n",
    "#                 print('here')\n",
    "                test_features.append(int(model.predict([testing_x[currentIndex-1]])=='B-ORG'))\n",
    "                test_features.append(int(model.predict([testing_x[currentIndex-1]])=='B-PER'))\n",
    "                test_features.append(int(model.predict([testing_x[currentIndex-1]])=='B-LOC'))\n",
    "                test_features.append(int(model.predict([testing_x[currentIndex-1]])=='B-MISC'))\n",
    "                test_features.append(int(model.predict([testing_x[currentIndex-1]])=='I-ORG'))\n",
    "                test_features.append(int(model.predict([testing_x[currentIndex-1]])=='I-PER'))\n",
    "                test_features.append(int(model.predict([testing_x[currentIndex-1]])=='I-LOC'))\n",
    "                test_features.append(int(model.predict([testing_x[currentIndex-1]])=='I-MISC'))\n",
    "                test_features.append(int(model.predict([testing_x[currentIndex-1]])=='O'))\n",
    "                test_features.append(int((test[m+1][n-1])=='NNP'))\n",
    "                test_features.append(int((test[m+1][n-1])=='NNPS'))\n",
    "                test_features.append(int((test[m+1][n-1])=='IN'))\n",
    "                test_features.append(int((test[m+1][n-1])=='JJ'))\n",
    "                test_features.append((int((test[m+1][n-1])=='VB')))\n",
    "                test_features.append((int((test[m+1][n-1])=='VBD')))\n",
    "                test_features.append(int(test[m][n-1]==','))\n",
    "#                 test_features.append(len(test[m][n-1]))\n",
    "                test_features.append(int(test[m][n-1][0].isupper()))#first letter capital\n",
    "                test_features.append(int(test[m][n-1].isupper()))#whole word capitalized\n",
    "                test_features.append(int(shape(test[m][n-1]) == 'abbreviation'))\n",
    "                test_features.append(int(shape(test[m][n-1]) == 'ending-dot'))\n",
    "                test_features.append(int(shape(test[m][n-1]) == 'wildcard'))\n",
    "                test_features.append(int(shape(test[m][n-1]) == 'mixedcase'))\n",
    "                test_features.append(int(shape(test[m][n-1]) == 'camelcase'))\n",
    "                test_features.append(int(shape(test[m][n-1]) == 'number'))\n",
    "                test_features.append(int(shape(test[m][n-1]) == 'punct'))\n",
    "                \n",
    "                if n < len(test[m])-1:\n",
    "                    test_features.append(int((test[m+1][n+1])=='NNP'))\n",
    "                    test_features.append(int((test[m+1][n+1])=='NNPS'))\n",
    "                    test_features.append(int((test[m+1][n+1])=='IN'))\n",
    "                    test_features.append(int((test[m+1][n+1])=='JJ'))\n",
    "                    test_features.append((int((test[m+1][n+1])=='POS')))\n",
    "                    test_features.append((int((test[m+1][n+1])=='RB')))\n",
    "                    test_features.append((int((test[m+1][n+1])=='VB')))\n",
    "                    test_features.append((int((test[m+1][n+1])=='VBD')))\n",
    "                    test_features.append(int(test[m][n+1]==','))\n",
    "    #                 test_features.append(len(test[m][n-1]))\n",
    "                    test_features.append(int(test[m][n+1][0].isupper()))#first letter capital\n",
    "                    test_features.append(int(test[m][n+1].isupper()))#whole word capitalized\n",
    "                    test_features.append(int(shape(test[m][n+1]) == 'abbreviation'))\n",
    "                    test_features.append(int(shape(test[m][n+1]) == 'ending-dot'))\n",
    "                    test_features.append(int(shape(test[m][n+1]) == 'wildcard'))\n",
    "                    test_features.append(int(shape(test[m][n+1]) == 'mixedcase'))\n",
    "                    test_features.append(int(shape(test[m][n+1]) == 'camelcase'))\n",
    "                    test_features.append(int(shape(test[m][n+1]) == 'number'))\n",
    "                    test_features.append(int(shape(test[m][n+1]) == 'punct'))\n",
    "                else:\n",
    "                    for i in range(25,43):\n",
    "                        test_features.append(0)\n",
    "            else:\n",
    "                for i in range(43):\n",
    "                    test_features.append(0)\n",
    "                    \n",
    "                    \n",
    "            test_features.append(int((test[m+1][n])=='NNP'))\n",
    "            test_features.append(int((test[m+1][n])=='NNPS'))\n",
    "            test_features.append(int(test[m][n][0].isupper()))\n",
    "            test_features.append(int(test[m][n].isupper()))\n",
    "            test_features.append(int('-' in test[m][n] and (len(test[m][n])>0)))\n",
    "            test_features.append(len(test[m][n]))\n",
    "            test_features.append(int(test[m][n].isalpha()))\n",
    "            test_features.append(int(shape(test[m][n]) == 'abbreviation'))\n",
    "            test_features.append(int(shape(test[m][n]) == 'ending-dot'))\n",
    "            test_features.append(int(shape(test[m][n]) == 'wildcard'))\n",
    "            test_features.append(int(shape(test[m][n]) == 'mixedcase'))\n",
    "            test_features.append(int(shape(test[m][n]) == 'camelcase'))\n",
    "            test_features.append(int(shape(test[m][n]) == 'number'))\n",
    "            test_features.append(int(shape(test[m][n]) == 'punct'))\n",
    "          \n",
    "#             print(\"test features\", test_features)\n",
    "            testing_x.append(test_features)\n",
    "            idk_x.append(test_features)\n",
    "            mini_preds.append(model.predict_proba([test_features]))\n",
    "            semifinal_preds.append(model.predict([test_features]))\n",
    "        tests_x.append(idk_x)\n",
    "        predictions.append(mini_preds)\n",
    "        final_preds.append(semifinal_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MEMM VITERBI ALGORITHM\n",
    "def viterbi_memm_o(line, probs):\n",
    "    categories = [\"B-LOC\", \"B-MISC\", \"B-ORG\", \"B-PER\", \"I-LOC\", \"I-MISC\", \"I-ORG\", \"I-PER\", \"O\"]\n",
    "    backpointer = np.zeros([len(categories), len(line)])\n",
    "    score = np.zeros([len(categories), len(line)])\n",
    "    \n",
    "    for i in range(len(categories)):\n",
    "        score[i][0] = probs[0][0][i] \n",
    "        backpointer[i][0] = 0\n",
    "        \n",
    "    for t in range(1, len(line)):\n",
    "        for i in range(len(categories)):\n",
    "            index = 0\n",
    "            saved_score = 0\n",
    "            for j in range(len(categories)):\n",
    "                current_score = score[j][t-1]*probs[t][0][i]\n",
    "                if current_score > saved_score:\n",
    "                    saved_score = current_score\n",
    "                    index = j\n",
    "            score[i][t] = saved_score\n",
    "            backpointer[i][t] = index\n",
    "    sequence = np.zeros(len(line))\n",
    "    max_s = 0\n",
    "    max_index = 0\n",
    "    for i in range(9):\n",
    "        if max_s < score[i][-1]:\n",
    "            max_s = score[i][-1]\n",
    "            max_index = i\n",
    "    sequence[-1] = max_index\n",
    "    char_sequence = []\n",
    "    for i in range(len(line)-2, -1, -1):\n",
    "        sequence[i] = backpointer[int(sequence[i+1])][i+1]\n",
    "    for i in range(len(line)):\n",
    "        char_sequence.append(categories[int(sequence[i])])\n",
    "    return char_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Going through test set and executing our MEMM Viterbi algorithm on the set\n",
    "tsv_file = open('test.txt', encoding=\"utf8\")\n",
    "tsv_reader = csv.reader(tsv_file, delimiter='\\t', quotechar=None)\n",
    "PER = []\n",
    "LOC = []\n",
    "ORG = []\n",
    "MISC = []\n",
    "indices = []\n",
    "tags = []\n",
    "baseline2_display = []\n",
    "baseline1_display = []\n",
    "display = []\n",
    "i = 0\n",
    "for row in tsv_reader:\n",
    "    if i%3 == 0:\n",
    "        index = int(i/3)\n",
    "\n",
    "        line_tags = viterbi_memm_o(row, predictions[index])\n",
    "        baseline1_display.append(baseline(row))\n",
    "        baseline2_display.append(baseline2(row))\n",
    "\n",
    "        display.append(line_tags)\n",
    "        for tag in line_tags:\n",
    "            tags.append(tag)\n",
    "    i+=1\n",
    "tsv_file = open('test.txt', encoding=\"utf8\")\n",
    "i = 0\n",
    "tsv_reader = csv.reader(tsv_file, delimiter=' ', quotechar=None)\n",
    "for row in tsv_reader:\n",
    "    if i%3 == 2:\n",
    "        for element in row:\n",
    "            indices.append(element)\n",
    "    i+= 1\n",
    "for i in range(len(tags)):\n",
    "    if \"PER\" in tags[i]:\n",
    "         tags[i] = \"PER\"\n",
    "    elif \"LOC\" in  tags[i]:\n",
    "         tags[i] = \"LOC\"\n",
    "    elif \"ORG\" in  tags[i]:\n",
    "         tags[i] = \"ORG\"\n",
    "    elif \"MISC\" in  tags[i]:\n",
    "         tags[i] = \"MISC\"\n",
    "    else:\n",
    "         tags[i] = \"O\"\n",
    "beginning = False\n",
    "log_tag = \"\"\n",
    "end = \"\"\n",
    "begin = \"\"\n",
    "intermediate = False\n",
    "for i in range(len(tags)):\n",
    "    if beginning and log_tag == tags[i]:\n",
    "        end = str(indices[i])\n",
    "    if beginning and not log_tag == tags[i]:\n",
    "        beginning = False\n",
    "        if \"PER\" in log_tag:\n",
    "            PER.append(begin+end)\n",
    "        elif \"LOC\" in log_tag:\n",
    "            LOC.append(begin+end)\n",
    "        elif \"ORG\" in log_tag:\n",
    "            ORG.append(begin+end)\n",
    "        elif \"MISC\" in log_tag:\n",
    "            MISC.append(begin+end)\n",
    "    if beginning == False and not tags[i] == 'O':\n",
    "        beginning = True\n",
    "        log_tag = tags[i]\n",
    "        begin = str(indices[i]) + \"-\"\n",
    "        end = str(indices[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WRITING PREDICTIONS TO CSV FOR SUBMISSION\n",
    "csv_per = \"\"\n",
    "csv_loc = \"\"\n",
    "csv_org = \"\"\n",
    "csv_misc = \"\"\n",
    "for i in PER:\n",
    "    csv_per += i + \" \"\n",
    "for i in LOC:\n",
    "    csv_loc += i + \" \"\n",
    "for i in ORG:\n",
    "    csv_org += i + \" \"\n",
    "for i in MISC:\n",
    "    csv_misc += i + \" \"\n",
    "with open('preds_memm.csv', 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile)\n",
    "    spamwriter.writerow([\"Type\", \"Prediction\"])\n",
    "    spamwriter.writerow([\"PER\", csv_per])\n",
    "    spamwriter.writerow([\"LOC\", csv_loc])\n",
    "    spamwriter.writerow([\"ORG\", csv_org])\n",
    "    spamwriter.writerow([\"MISC\", csv_misc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MEMM Validation + Baseline Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting validation set to feature vectors\n",
    "validating_x = []\n",
    "validating_y = []\n",
    "predictions_val = []\n",
    "for m in range (len(validation)):\n",
    "    mini_preds = []\n",
    "    for n in range(len(validation[m])):\n",
    "        currentIndex = n\n",
    "        test_features = []\n",
    "        if n > 0:\n",
    "#                 print('here')\n",
    "            test_features.append(int(validation_tags[m][n-1] =='B-ORG'))\n",
    "            test_features.append(int(validation_tags[m][n-1]=='B-PER'))\n",
    "            test_features.append(int(validation_tags[m][n-1]=='B-LOC'))\n",
    "            test_features.append(int(validation_tags[m][n-1]=='B-MISC'))\n",
    "            test_features.append(int(validation_tags[m][n-1]=='I-ORG'))\n",
    "            test_features.append(int(validation_tags[m][n-1]=='I-PER'))\n",
    "            test_features.append(int(validation_tags[m][n-1]=='I-LOC'))\n",
    "            test_features.append(int(validation_tags[m][n-1]=='I-MISC'))\n",
    "            test_features.append(int(validation_tags[m][n-1]=='O'))\n",
    "            test_features.append(int((validation_pos[m][n-1])=='NNP'))\n",
    "            test_features.append(int((validation_pos[m][n-1])=='NNPS'))\n",
    "            test_features.append(int((validation_pos[m][n-1])=='IN'))\n",
    "            test_features.append(int((validation_pos[m][n-1])=='JJ'))\n",
    "            test_features.append((int((validation_pos[m][n-1])=='VB')))\n",
    "            test_features.append((int((validation_pos[m][n-1])=='VBD')))\n",
    "            test_features.append(int(validation[m][n-1]==','))\n",
    "#                 test_features.append(len(test[m][n-1]))\n",
    "            test_features.append(int(validation[m][n-1][0].isupper()))#first letter capital\n",
    "            test_features.append(int(validation[m][n-1].isupper()))#whole word capitalized\n",
    "            test_features.append(int(shape(validation[m][n-1]) == 'abbreviation'))\n",
    "            test_features.append(int(shape(validation[m][n-1]) == 'ending-dot'))\n",
    "            test_features.append(int(shape(validation[m][n-1]) == 'wildcard'))\n",
    "            test_features.append(int(shape(validation[m][n-1]) == 'mixedcase'))\n",
    "            test_features.append(int(shape(validation[m][n-1]) == 'camelcase'))\n",
    "            test_features.append(int(shape(validation[m][n-1]) == 'number'))\n",
    "            test_features.append(int(shape(validation[m][n-1]) == 'punct'))\n",
    "            \n",
    "            if n < len(validation[m])-1:\n",
    "                test_features.append(int((validation_pos[m][n+1])=='NNP'))\n",
    "                test_features.append(int((validation_pos[m][n+1])=='NNPS'))\n",
    "                test_features.append(int((validation_pos[m][n+1])=='IN'))\n",
    "                test_features.append(int((validation_pos[m][n+1])=='JJ'))\n",
    "                test_features.append((int((validation_pos[m][n+1])=='POS')))\n",
    "                test_features.append((int((validation_pos[m][n+1])=='RB')))\n",
    "                test_features.append((int((validation_pos[m][n+1])=='VB')))\n",
    "                test_features.append((int((validation_pos[m][n+1])=='VBD')))\n",
    "                test_features.append(int(validation[m][n+1]==','))\n",
    "#                 test_features.append(len(test[m][n-1]))\n",
    "                test_features.append(int(validation[m][n+1][0].isupper()))#first letter capital\n",
    "                test_features.append(int(validation[m][n+1].isupper()))#whole word capitalized\n",
    "                test_features.append(int(shape(validation[m][n+1]) == 'abbreviation'))\n",
    "                test_features.append(int(shape(validation[m][n+1]) == 'ending-dot'))\n",
    "                test_features.append(int(shape(validation[m][n+1]) == 'wildcard'))\n",
    "                test_features.append(int(shape(validation[m][n+1]) == 'mixedcase'))\n",
    "                test_features.append(int(shape(validation[m][n+1]) == 'camelcase'))\n",
    "                test_features.append(int(shape(validation[m][n+1]) == 'number'))\n",
    "                test_features.append(int(shape(validation[m][n+1]) == 'punct'))\n",
    "            else:\n",
    "                for i in range(25,43):\n",
    "                    test_features.append(0)\n",
    "        else:\n",
    "            for i in range(43):\n",
    "                test_features.append(0)\n",
    "\n",
    "\n",
    "        test_features.append(int((validation_pos[m][n])=='NNP'))\n",
    "        test_features.append(int((validation_pos[m][n])=='NNPS'))\n",
    "        test_features.append(int(validation[m][n][0].isupper()))\n",
    "        test_features.append(int(validation[m][n].isupper()))\n",
    "        test_features.append(int('-' in validation[m][n] and (len(validation[m][n])>0)))\n",
    "        test_features.append(len(validation[m][n]))\n",
    "        test_features.append(int(validation[m][n].isalpha()))\n",
    "        test_features.append(int(shape(validation[m][n]) == 'abbreviation'))\n",
    "        test_features.append(int(shape(validation[m][n]) == 'ending-dot'))\n",
    "        test_features.append(int(shape(validation[m][n]) == 'wildcard'))\n",
    "        test_features.append(int(shape(validation[m][n]) == 'mixedcase'))\n",
    "        test_features.append(int(shape(validation[m][n]) == 'camelcase'))\n",
    "        test_features.append(int(shape(validation[m][n]) == 'number'))\n",
    "        test_features.append(int(shape(validation[m][n]) == 'punct'))\n",
    "\n",
    "\n",
    "#             print(\"test features\", test_features)\n",
    "        validating_x.append(test_features)\n",
    "        validating_y.append(validation_tags[m][n])\n",
    "        mini_preds.append(model.predict_proba([test_features]))\n",
    "\n",
    "    predictions_val.append(mini_preds)\n",
    "\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First and Second Baseline Models from HMM File\n",
    "def baseline(line):\n",
    "    tags = []\n",
    "    for element in line:\n",
    "        if element not in vocabulary:\n",
    "            element = \"<UNK>\"\n",
    "        if element == \"<UNK>\":\n",
    "            tags.append(\"O\")\n",
    "        else:\n",
    "            vals = train_words[element]\n",
    "            most_likely = max(vals, key=train_words[element].get)\n",
    "            tags.append(most_likely)\n",
    "    return tags\n",
    "\n",
    "def baseline2(line):\n",
    "    tags = []\n",
    "    for element in line:\n",
    "        if element not in vocabulary:\n",
    "            element = \"<UNK>\"\n",
    "        if element == \"<UNK>\":\n",
    "            tags.append(\"O\")\n",
    "        else:\n",
    "            tags.append(np.random.choice(list(train_words[element])))\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Precision, Recall, F-Score on validation set\n",
    "memm_viterbi = []\n",
    "baseline1_val = []\n",
    "baseline2_val = []\n",
    "def check_val(method,validation, validation_tags):\n",
    "    correct = 0\n",
    "    guessed = 0\n",
    "    total = 0\n",
    "    for i in range(len(validation)):\n",
    "        tags = []\n",
    "        if method == 'viterbi':\n",
    "            guess_line = viterbi_memm_o(validation[i], predictions_val[i])\n",
    "            memm_viterbi.append(guess_line)\n",
    "        elif method == 'baseline1':\n",
    "            guess_line = baseline(validation[i])\n",
    "            baseline1_val.append(guess_line)\n",
    "        else:\n",
    "            guess_line = baseline2(validation[i])\n",
    "            baseline2_val.append(guess_line)\n",
    "        for tag in range(len(guess_line)):\n",
    "            if \"PER\" in guess_line[tag]:\n",
    "                tags.append(\"PER\")\n",
    "            elif \"LOC\" in guess_line[tag]:\n",
    "                tags.append(\"LOC\")\n",
    "            elif \"ORG\" in guess_line[tag]:\n",
    "                tags.append(\"ORG\")\n",
    "            elif \"MISC\" in guess_line[tag]:\n",
    "                tags.append(\"MISC\")\n",
    "            else:\n",
    "                tags.append(\"O\")\n",
    "        for tag in range(len(validation_tags[i])):\n",
    "            if \"PER\" in validation_tags[i][tag]:\n",
    "                validation_tags[i][tag] = \"PER\"\n",
    "            elif \"LOC\" in validation_tags[i][tag]:\n",
    "                validation_tags[i][tag] = \"LOC\"\n",
    "            elif \"ORG\" in validation_tags[i][tag]:\n",
    "                validation_tags[i][tag] = \"ORG\"\n",
    "            elif \"MISC\" in validation_tags[i][tag]:\n",
    "                validation_tags[i][tag] = \"MISC\"\n",
    "            else:\n",
    "                validation_tags[i][tag] = \"O\"\n",
    "#         print(tags, validation_tags[i])\n",
    "        for tag in range(len(validation_tags[i])):\n",
    "            if tags[tag] == \"O\":\n",
    "                continue\n",
    "#             print(tags[tag] == validation_tags[i][tag])\n",
    "            correct += (tags[tag] == validation_tags[i][tag])\n",
    "        for j in guess_line:\n",
    "            if not j == 'O':\n",
    "                guessed += 1\n",
    "        for k in validation_tags[i]:\n",
    "            if not k == 'O':\n",
    "                total += 1\n",
    "    precision = correct/guessed\n",
    "    recall = correct/total\n",
    "    fscore = 2*precision*recall/(precision+recall)\n",
    "    return precision, recall, fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5407725321888412 0.3152317880794702 0.3982893268873188\n"
     ]
    }
   ],
   "source": [
    "precision, recall, fscore = check_val('viterbi', validation, validation_tags)\n",
    "print(precision, recall, fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8679379789698806 0.7167034584253127 0.7851039819442205\n"
     ]
    }
   ],
   "source": [
    "precision, recall, fscore = check_val('baseline1', validation, validation_tags)\n",
    "print(precision, recall, fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32853621690387214 0.6080941869021339 0.4265950856906876\n"
     ]
    }
   ],
   "source": [
    "precision, recall, fscore = check_val('baseline2', validation, validation_tags)\n",
    "print(precision, recall, fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(display[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['West', 'Ham', '3', '1', '1', '1', '3', '4', '4']\n"
     ]
    }
   ],
   "source": [
    "print(test[135])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-LOC', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(baseline1_display[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'I-ORG']\n"
     ]
    }
   ],
   "source": [
    "print(baseline2_display[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
